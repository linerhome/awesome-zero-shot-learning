<h1> 
  Zero-shot-Learning
</h1>

<p>
  <a href="https://github.com/sindresorhus/awesome"><img src="https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667" alt="Awesome" data-canonical-src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" style="max-width:100%;">
  </a>
</p>

<p>
  A curated list of papers on zero-shot learning.
</p>

<h2>
  <a id="user-content-contributing" class="anchor" aria-hidden="true" href="#contributing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z">
    </path>
    </svg>
  </a>
  Contributing
</h2>

<p>
  Please feel free to send me <a href="https://github.com/shubham-krishna/aweosme-zero-shot-learning/pulls">pull requests
  </a> or email (<a href="mailto:shubhamkrishna.ism@gmail.com">shubhamkrishna.ism@gmail.com</a>) to add links and for new suggestions on how to make this repository more useful.
</p>

<h2><a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
  </svg>
  </a>Table of Contents
</h2>

<ul>
<li><a href="#Papers">Papers</a></li>
</ul>

<h3><a id="user-content-papers" class="anchor" aria-hidden="true" href="#papers"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
  </svg>
  </a>
  Papers
</h3>
  
<h4><a id="user-content-cvpr-2019" class="anchor" aria-hidden="true" href="#neurips-2019"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
  </svg>
  </a>
  CVPR 2019
</h4>  

<ul>
<li> Michael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, Eric P. Xing. "Rethinking Knowledge Graph Propagation for Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Kampffmeyer_Rethinking_Knowledge_Graph_Propagation_for_Zero-Shot_Learning_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Yongqin Xian, Saurabh Sharma, Bernt Schiele, Zeynep Akata. "F-VAEGAN-D2: A Feature Generating Framework for Any-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Xian_F-VAEGAN-D2_A_Feature_Generating_Framework_for_Any-Shot_Learning_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
   <li> Pengkai Zhu, Hanxiao Wang, Venkatesh Saligrama. "Generalized Zero-Shot Recognition Based on Visually Semantic Embedding" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Generalized_Zero-Shot_Recognition_Based_on_Visually_Semantic_Embedding_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Edgar Schonfeld, Sayna Ebrahimi, Samarth Sinha, Trevor Darrell, Zeynep Akata. "Generalized Zero- and Few-Shot Learning via Aligned Variational Autoencoders" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Schonfeld_Generalized_Zero-_and_Few-Shot_Learning_via_Aligned_Variational_Autoencoders_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Anjan Dutta, Zeynep Akata. "Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-Based Image Retrieval" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Dutta_Semantically_Tied_Paired_Cycle_Consistency_for_Zero-Shot_Sketch-Based_Image_Retrieval_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Michael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, Eric P. Xing. "Rethinking Knowledge Graph Propagation for Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Kampffmeyer_Rethinking_Knowledge_Graph_Propagation_for_Zero-Shot_Learning_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Mert Bulent Sariyildiz, Ramazan Gokberk Cinbis. "Gradient Matching Generative Networks for Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Sariyildiz_Gradient_Matching_Generative_Networks_for_Zero-Shot_Learning_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Xin Wang, Fisher Yu, Ruth Wang, Trevor Darrell, Joseph E. Gonzalez. "TAFE-Net: Task-Aware Feature Embeddings for Low Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_TAFE-Net_Task-Aware_Feature_Embeddings_for_Low_Shot_Learning_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
 <li> Yaojie Liu, Joel Stehouwer, Amin Jourabloo, Xiaoming Liu. "Deep Tree Learning for Zero-Shot Face Anti-Spoofing" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Deep_Tree_Learning_for_Zero-Shot_Face_Anti-Spoofing_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Jingjing Li, Mengmeng Jing, Ke Lu, Zhengming Ding, Lei Zhu, Zi Huang. "Leveraging the Invariant Side of Generative Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Leveraging_the_Invariant_Side_of_Generative_Zero-Shot_Learning_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
 <li> Sounak Dey, Pau Riba, Anjan Dutta, Josep Llados, Yi-Zhe Song. "Doodle to Search: Practical Zero-Shot Sketch-Based Image Retrieval" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Dey_Doodle_to_Search_Practical_Zero-Shot_Sketch-Based_Image_Retrieval_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
 <li> Sounak Dey, Pau Riba, Anjan Dutta, Josep Llados, Yi-Zhe Song. "Doodle to Search: Practical Zero-Shot Sketch-Based Image Retrieval" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Dey_Doodle_to_Search_Practical_Zero-Shot_Sketch-Based_Image_Retrieval_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Guo-Sen Xie, Li Liu, Xiaobo Jin, Fan Zhu, Zheng Zhang, Jie Qin, Yazhou Yao, Ling Shao. "Attentive Region Embedding Network for Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Xie_Attentive_Region_Embedding_Network_for_Zero-Shot_Learning_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Devraj Mandal, Sanath Narayan, Sai Kumar Dwivedi, Vikram Gupta, Shuaib Ahmed, Fahad Shahbaz Khan, Ling Shao. "Out-Of-Distribution Detection for Generalized Zero-Shot Action Recognition" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Mandal_Out-Of-Distribution_Detection_for_Generalized_Zero-Shot_Action_Recognition_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> He Huang, Changhu Wang, Philip S. Yu, Chang-Dong Wang. "Generative Dual Adversarial Network for Generalized Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Huang_Generative_Dual_Adversarial_Network_for_Generalized_Zero-Shot_Learning_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Binghui Chen, Weihong Deng. "Hybrid-Attention Based Decoupled Metric Learning for Zero-Shot Image Retrieval" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Hybrid-Attention_Based_Decoupled_Metric_Learning_for_Zero-Shot_Image_Retrieval_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Akanksha Paul, Narayanan C. Krishnan, Prateek Munjal. "Semantically Aligned Bias Reducing Zero Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Paul_Semantically_Aligned_Bias_Reducing_Zero_Shot_Learning_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Jin Li, Xuguang Lan, Yang Liu, Le Wang, Nanning Zheng. "Compressing Unknown Images With Product Quantizer for Efficient Zero-Shot Classification" 
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Compressing_Unknown_Images_With_Product_Quantizer_for_Efficient_Zero-Shot_Classification_CVPR_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  

  
 </ul> 
 
 <h4><a id="user-content-iccv-2019" class="anchor" aria-hidden="true" href="#iccv-2019"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
  </svg>
  </a>
  ICCV 2019
</h4>

<ul>
<li> Senthil Purushwalkam, Maximilian Nickel, Abhinav Gupta, Marc'Aurelio Ranzato. "Task-Driven Modular Networks for Zero-Shot Compositional Learning" 
  <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Purushwalkam_Task-Driven_Modular_Networks_for_Zero-Shot_Compositional_Learning_ICCV_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Qi Dong, Shaogang Gong, Xiatian Zhu. "Person Search by Text Attribute Query As Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Dong_Person_Search_by_Text_Attribute_Query_As_Zero-Shot_Learning_ICCV_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
   <li> Mohamed Elhoseiny, Mohamed Elfeki. "Creativity Inspired Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Elhoseiny_Creativity_Inspired_Zero-Shot_Learning_ICCV_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Fadime Sener, Angela Yao. "Zero-Shot Anticipation for Instructional Activities" 
  <a href=http://openaccess.thecvf.com/content_ICCV_2019/papers/Sener_Zero-Shot_Anticipation_for_Instructional_Activities_ICCV_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Huajie Jiang, Ruiping Wang, Shiguang Shan, Xilin Chen. "Transferable Contrastive Network for Generalized Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Jiang_Transferable_Contrastive_Network_for_Generalized_Zero-Shot_Learning_ICCV_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Qing Liu, Lingxi Xie, Huiyu Wang, Alan L. Yuille. "Semantic-Aware Knowledge Preservation for Zero-Shot Sketch-Based Image Retrieval" 
  <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Semantic-Aware_Knowledge_Preservation_for_Zero-Shot_Sketch-Based_Image_Retrieval_ICCV_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Chi Zhan, Dongyu She, Sicheng Zhao, Ming-Ming Cheng, Jufeng Yang. "Zero-Shot Emotion Recognition via Affective Structural Embedding" 
  <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhan_Zero-Shot_Emotion_Recognition_via_Affective_Structural_Embedding_ICCV_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
  <li> Yizhe Zhu, Jianwen Xie, Bingchen Liu, Ahmed Elgammal. "Learning Feature-to-Feature Translator by Alternating Back-Propagation for Generative Zero-Shot Learning" 
  <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhu_Learning_Feature-to-Feature_Translator_by_Alternating_Back-Propagation_for_Generative_Zero-Shot_Learning_ICCV_2019_paper.pdf" rel="nofollow">[pdf]</a></li>
  
 
  
</ul> 

<h4><a id="user-content-aaai-2019" class="anchor" aria-hidden="true" href="#iccv-2019"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
  </svg>
  </a>
  AAAI 2019
</h4>

<ul>
<li> Yuchen Guo, Guiguang Ding, Jungong Han, Xiaohan Ding, Sicheng Zhao, Zheng Wang, Chenggang Yan, Qionghai Dai. "Dual-View Ranking with Hardness Assessment for Zero-Shot Learning" 
  <a href="https://www.aaai.org/ojs/index.php/AAAI/article/view/4850/4723" rel="nofollow">[pdf]</a></li>
  
</ul>  

<h4><a id="user-content-aaai-2019" class="anchor" aria-hidden="true" href="#iccv-2019"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path>
  </svg>
  </a>
  NeurIPS 2019
</h4>

<ul>
<li> Paul Micaelli,Amos Storkey. "Zero-shot Knowledge Transfer via Adversarial Belief Matching" 
  <a href="http://papers.nips.cc/paper/9151-zero-shot-knowledge-transfer-via-adversarial-belief-matching.pdf" rel="nofollow">[pdf]</a></li>
  
</ul> 
  
  
  
  
  
  
